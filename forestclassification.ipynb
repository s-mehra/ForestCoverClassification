{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest Cover Classification\n",
    "\n",
    "A deep learning model to predict forest cover based on various cartographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
      "0       2596      51      3                               258   \n",
      "1       2590      56      2                               212   \n",
      "2       2804     139      9                               268   \n",
      "3       2785     155     18                               242   \n",
      "4       2595      45      2                               153   \n",
      "\n",
      "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
      "0                               0                              510   \n",
      "1                              -6                              390   \n",
      "2                              65                             3180   \n",
      "3                             118                             3090   \n",
      "4                              -1                              391   \n",
      "\n",
      "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
      "0            221             232            148   \n",
      "1            220             235            151   \n",
      "2            234             238            135   \n",
      "3            238             238            122   \n",
      "4            220             234            150   \n",
      "\n",
      "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
      "0                                6279  ...            0            0   \n",
      "1                                6225  ...            0            0   \n",
      "2                                6121  ...            0            0   \n",
      "3                                6211  ...            0            0   \n",
      "4                                6172  ...            0            0   \n",
      "\n",
      "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   Soil_Type39  Soil_Type40  class  \n",
      "0            0            0      5  \n",
      "1            0            0      5  \n",
      "2            0            0      2  \n",
      "3            0            0      2  \n",
      "4            0            0      5  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581012 entries, 0 to 581011\n",
      "Data columns (total 55 columns):\n",
      " #   Column                              Non-Null Count   Dtype\n",
      "---  ------                              --------------   -----\n",
      " 0   Elevation                           581012 non-null  int64\n",
      " 1   Aspect                              581012 non-null  int64\n",
      " 2   Slope                               581012 non-null  int64\n",
      " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n",
      " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64\n",
      " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64\n",
      " 6   Hillshade_9am                       581012 non-null  int64\n",
      " 7   Hillshade_Noon                      581012 non-null  int64\n",
      " 8   Hillshade_3pm                       581012 non-null  int64\n",
      " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n",
      " 10  Wilderness_Area1                    581012 non-null  int64\n",
      " 11  Wilderness_Area2                    581012 non-null  int64\n",
      " 12  Wilderness_Area3                    581012 non-null  int64\n",
      " 13  Wilderness_Area4                    581012 non-null  int64\n",
      " 14  Soil_Type1                          581012 non-null  int64\n",
      " 15  Soil_Type2                          581012 non-null  int64\n",
      " 16  Soil_Type3                          581012 non-null  int64\n",
      " 17  Soil_Type4                          581012 non-null  int64\n",
      " 18  Soil_Type5                          581012 non-null  int64\n",
      " 19  Soil_Type6                          581012 non-null  int64\n",
      " 20  Soil_Type7                          581012 non-null  int64\n",
      " 21  Soil_Type8                          581012 non-null  int64\n",
      " 22  Soil_Type9                          581012 non-null  int64\n",
      " 23  Soil_Type10                         581012 non-null  int64\n",
      " 24  Soil_Type11                         581012 non-null  int64\n",
      " 25  Soil_Type12                         581012 non-null  int64\n",
      " 26  Soil_Type13                         581012 non-null  int64\n",
      " 27  Soil_Type14                         581012 non-null  int64\n",
      " 28  Soil_Type15                         581012 non-null  int64\n",
      " 29  Soil_Type16                         581012 non-null  int64\n",
      " 30  Soil_Type17                         581012 non-null  int64\n",
      " 31  Soil_Type18                         581012 non-null  int64\n",
      " 32  Soil_Type19                         581012 non-null  int64\n",
      " 33  Soil_Type20                         581012 non-null  int64\n",
      " 34  Soil_Type21                         581012 non-null  int64\n",
      " 35  Soil_Type22                         581012 non-null  int64\n",
      " 36  Soil_Type23                         581012 non-null  int64\n",
      " 37  Soil_Type24                         581012 non-null  int64\n",
      " 38  Soil_Type25                         581012 non-null  int64\n",
      " 39  Soil_Type26                         581012 non-null  int64\n",
      " 40  Soil_Type27                         581012 non-null  int64\n",
      " 41  Soil_Type28                         581012 non-null  int64\n",
      " 42  Soil_Type29                         581012 non-null  int64\n",
      " 43  Soil_Type30                         581012 non-null  int64\n",
      " 44  Soil_Type31                         581012 non-null  int64\n",
      " 45  Soil_Type32                         581012 non-null  int64\n",
      " 46  Soil_Type33                         581012 non-null  int64\n",
      " 47  Soil_Type34                         581012 non-null  int64\n",
      " 48  Soil_Type35                         581012 non-null  int64\n",
      " 49  Soil_Type36                         581012 non-null  int64\n",
      " 50  Soil_Type37                         581012 non-null  int64\n",
      " 51  Soil_Type38                         581012 non-null  int64\n",
      " 52  Soil_Type39                         581012 non-null  int64\n",
      " 53  Soil_Type40                         581012 non-null  int64\n",
      " 54  class                               581012 non-null  int64\n",
      "dtypes: int64(55)\n",
      "memory usage: 243.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sweetviz as sv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras;\n",
    "from keras import Sequential;\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some helper methods to build and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_features):\n",
    "    '''\n",
    "    Build and compile model\n",
    "    Takes number of features to use as input dimensions\n",
    "    Returns a keras model object\n",
    "    '''\n",
    "    classifier = Sequential()\n",
    "    classifier.add(layers.Dense(64, input_dim=num_features, activation='relu'))\n",
    "    classifier.add(layers.Dropout(0.3))\n",
    "    classifier.add(layers.Dense(32, activation='relu'))\n",
    "    classifier.add(layers.Dropout(0.3))\n",
    "    classifier.add(layers.Dense(8, activation='softmax'))\n",
    "    \n",
    "    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, param):\n",
    "    '''\n",
    "    Plots model performance over number of epochs\n",
    "    Depending on param passed, plots either accuracy or loss\n",
    "    '''\n",
    "    if param == 'accuracy':\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "    elif param == 'loss':\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(class_names, y_pred, y_test):\n",
    "    '''\n",
    "    Computes a confusion matrix an plots a heatmap based on the matrix\n",
    "    '''\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    heatmap = sns.heatmap(cm, fmt='g', cmap='Blues', annot=True, ax=ax)\n",
    "    ax.set_xlabel('Predicted Class')\n",
    "    ax.set_ylabel('True Class')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(class_names)\n",
    "    ax.yaxis.set_ticklabels(class_names)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the helper functions, we can analyze the data and build and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset = pd.read_csv('cover_data.csv')\n",
    "\n",
    "    #EDA\n",
    "    report = sv.analyze(dataset)\n",
    "    report.show_html()\n",
    "\n",
    "    columns = dataset.columns.to_list()\n",
    "    features, label = columns[:-1], columns[-1]\n",
    "    \n",
    "    raw_data = dataset.values\n",
    "    X, y = raw_data[:, :-1], raw_data[:, -1]\n",
    "\n",
    "    # Split into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "    # normalize data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    #building model\n",
    "    num_features = len(features)\n",
    "    model = build_model(num_features)\n",
    "    \n",
    "    #model summary\n",
    "    print(\"Model Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 1024\n",
    "    earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=3)\n",
    "    history = model.fit(X_train_normalized, y_train, epochs=num_epochs, batch_size=batch_size, callbacks=[earlystop_callback], validation_split=0.1, verbose=1)\n",
    "\n",
    "    plot_history(history, 'accuracy')\n",
    "    plot_history(history, 'loss')\n",
    "\n",
    "    score = model.evaluate(X_test_normalized, y_test, verbose=0)\n",
    "    print(f'Test loss: {score[0]}')\n",
    "    print(f'Test accuracy: {score[1]}')\n",
    "\n",
    "    y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    class_names = ['Spruce/Fir', 'Lodgepole Pine',\n",
    "                   'Ponderosa Pine', 'Cottonwood/Willow',\n",
    "                   'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "    plot_heatmap(class_names, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
